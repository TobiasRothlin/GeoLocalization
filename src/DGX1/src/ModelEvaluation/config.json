{
    "Runs": [
        {
            "ModelConfig": {
                "RunName": "CLIP",
                "BaseModel": "openai/clip-vit-large-patch14-336",
                "Discripiton": "CLIP with ViT base model",
                "ImageWidth": 336,
                "ImageHeight": 336,
                "UseCenterCrop": true,
                "ImageMean": [
                    0.48145466,
                    0.4578275,
                    0.40821073
                ],
                "ImageStd": [
                    0.26862954,
                    0.26130258,
                    0.27577711
                ],
                "StandardizationCoordinates": true,
                "LoadFromCheckpoint": "/home/tobias.rothlin/data/TrainingSnapshots/run_2/model_208000.pt"
            },
            "TestConfig": {
                "TrainBatchSize": 128,
                "TestBatchSize": 128,
                "NumWorkers": 8,
                "PersistantWorkers": true,
                "PrefetchFactor": 8,
                "LogModelOutput": true

            }
        }
    ]
}