{
    "Runs": [
        {
            "ModelConfig": {
                "RunName": "CLIP",
                "BaseModel": "openai/clip-vit-large-patch14-336",
                "Discripiton": "CLIP with ViT base model",
                "ImageWidth": 336,
                "ImageHeight": 336,
                "UseCenterCrop": true,
                "ImageMean": [
                    0.48145466,
                    0.4578275,
                    0.40821073
                ],
                "ImageStd": [
                    0.26862954,
                    0.26130258,
                    0.27577711
                ],
                "StandardizationCoordinates": true
            },
            "TrainingConfig": {
                "TrainBatchSize": 2,
                "TestBatchSize": 2,
                "Epochs": 5,
                "NumWorkers": 8,
                "PersistantWorkers": true,
                "PrefetchFactor": 8,
                "SaveEvery": 1000,
                "SnapshotPath": "/home/tobias.rothlin/data/TrainingSnapshots",
                "GradientAccumulationSteps": 128,
                "LearningRate": 1e-6,
                "Amsgrad": true,
                "WeightDecay": 1e-4,
                "Betas": [
                    0.9,
                    0.98
                ],
                "Gamma": 0.9,
                "LogModelOutput": true

            }
        }
    ]
}